# Performance Fix - CPU & Memory Usage

## Problem

The Flask application was consuming excessive resources in production:
- **898m CPU** (almost 1 full core) - causing node CPU usage to spike to 108%
- **1023Mi memory** (hitting the 1Gi limit) - causing pod evictions
- Cluster entering scaling and eviction spiral
- Application timing out and becoming inaccessible

## Root Cause

The application had heavy dependencies from the Obsidian CLI tool (`obsidian_maker.py`) that were being loaded in the production web app:

### Heavy Dependencies (REMOVED):
1. **`numba==0.62.1`** + **`llvmlite==0.45.1`** - JIT compiler (~200MB memory footprint)
2. **`scipy==1.16.2`** - Scientific computing library
3. **`numpy==2.2.6`** - Large numeric library
4. **`pandas==2.3.3`** - Data analysis library
5. **`opencv-python-headless==4.12.0.88`** - Computer vision library (massive)
6. **`obsidiantools==0.11.0`** - Only needed for CLI, not web app
7. **`z3-solver==4.15.3.0`** - Theorem prover (extremely heavy)
8. **`sympy==1.14.0`** - Symbolic math
9. **`networkx==3.5`** - Graph theory library
10. **`imageio==2.37.0`** - Image I/O with heavy codecs

**Impact:** With 4 workers Ã— ~250MB per worker = **1GB memory** just from imports!

## Solution

### 1. Created Minimal Requirements (`requirements.web.txt`)

Separated production dependencies from development/CLI dependencies:
- Core web framework (Flask, gunicorn)
- Auth (auth0-python, Authlib, PyJWT)
- Database (mongoengine, pymongo)
- Payment (stripe)
- AI (openai)
- FastAPI for API routes
- Minimal image processing (pillow only)

**Removed:** All scientific computing, computer vision, and CLI-only dependencies.

### 2. Optimized Dockerfile

**Before:**
```dockerfile
# Used full requirements.txt with all heavy dependencies
ADD ./requirements.txt /app/requirements.txt
RUN pip install --no-cache-dir -r requirements.txt
RUN pip install --no-cache-dir gunicorn

# 4 workers with --preload flag
CMD ["gunicorn", "app:app", "-b", "0.0.0.0:80", "--workers", "4", "--preload", "--timeout", "120"]
```

**After:**
```dockerfile
# Use minimal web requirements
ADD ./requirements.web.txt /app/requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# 2 workers (no --preload to avoid DB connection issues)
CMD ["gunicorn", "app:app", "-b", "0.0.0.0:80", "--workers", "2", "--timeout", "120"]
```

**Changes:**
- Use `requirements.web.txt` instead of `requirements.txt`
- Reduce from 4 workers to 2 (less memory per pod)
- Remove `--preload` flag (was causing health check timeouts)

### 3. Adjusted Resource Limits

**Before:** No limits (commented out)

**After:**
```yaml
resources:
  requests:
    memory: "256Mi"
    cpu: "100m"
  limits:
    memory: "512Mi"
    cpu: "500m"
```

### 4. Increased Health Check Timeouts

The app was timing out during health checks with the default 3-5 second timeouts.

**After:**
```yaml
livenessProbe:
  httpGet:
    path: /api/health
    port: 80
  initialDelaySeconds: 45
  periodSeconds: 15
  timeoutSeconds: 10
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /api/health
    port: 80
  initialDelaySeconds: 20
  periodSeconds: 10
  timeoutSeconds: 10
  failureThreshold: 3
```

### 5. Updated docker-compose for Local Development

Local development still needs the full dependencies for CLI tools:

```yaml
command: sh -c "pip install -q -r requirements.txt && flask --app app:app --debug run --host 0.0.0.0 --port 80"
```

This installs `requirements.txt` (full dependencies) at runtime, so you can still use Obsidian tools locally.

## Results

### Resource Usage Comparison

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| CPU | 898m | 2m | **99.7% reduction** |
| Memory | 1023Mi | 214Mi | **79% reduction** |
| Workers | 4 | 2 | 50% reduction |
| Container Size | ~400MB | ~109MB | 73% reduction |

### Cluster Health

**Before:**
- Node CPU: 108% (overloaded)
- Pods being evicted
- Application timing out

**After:**
- Node CPU: 3-9% (healthy)
- No evictions
- Application responsive

## Files Changed

1. **`requirements.web.txt`** - New minimal production dependencies
2. **`Dockerfile`** - Use minimal requirements, 2 workers, no --preload
3. **`deployment/service.yaml`** - Resource limits, increased health check timeouts
4. **`docker-compose.yaml`** - Install full requirements at runtime for local dev

## Deployment

```bash
./deploy.sh
```

The deploy script:
1. Builds Docker image with minimal dependencies
2. Pushes to Docker Hub
3. Updates Kubernetes deployment
4. Performs rolling update (zero downtime)

## Development Workflow

- **Local development:** Use `docker-compose up` - installs full `requirements.txt` at runtime
- **Production:** Uses pre-built image with `requirements.web.txt` (minimal dependencies)
- **CLI tools:** Run locally with full `requirements.txt` installed

## Notes

- The original `requirements.txt` is preserved for local development and CLI usage
- Production only needs web-specific dependencies
- All Obsidian-related tools (`obsidian_maker.py`) work locally with full dependencies
- Background removal was already handled by OpenAI's `background="transparent"` parameter, so rembg dependencies were unnecessary
